{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc4bb816",
   "metadata": {},
   "source": [
    "# VLM Chart Pattern Analyzer - Google Colab Benchmark\n",
    "\n",
    "This notebook runs VLM inference on chart images and outputs results to CSV.\n",
    "\n",
    "Upload your chart images or mount Google Drive with images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b30bd1b",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Set the parameters for the benchmark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1efbd9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Benchmark Parameters\n",
    "#@param {type:\"string\"}\n",
    "model_id = \"qwen2-vl-2b\" #@param [\"qwen2-vl-2b\", \"HuggingFaceTB/SmolVLM2-2.2B-Instruct\", \"other\"] {allow-input: true}\n",
    "#@param {type:\"string\"}\n",
    "precision = \"fp16\" #@param [\"fp32\", \"fp16\", \"int8\", \"int4\"]\n",
    "#@param {type:\"boolean\"}\n",
    "use_gpu = True #@param {type:\"boolean\"}\n",
    "#@param {type:\"string\"}\n",
    "hf_token = \"\" #@param {type:\"string\"}\n",
    "#@param {type:\"integer\"}\n",
    "image_limit = 0 #@param {type:\"integer\"}\n",
    "\n",
    "print(f\"Model ID: {model_id}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Use GPU: {use_gpu}\")\n",
    "print(f\"Image limit: {image_limit}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e790056",
   "metadata": {},
   "source": [
    "## Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0592e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers torch torchvision torchaudio --quiet\n",
    "!pip install huggingface_hub --quiet\n",
    "!pip install pillow --quiet\n",
    "!pip install accelerate --quiet\n",
    "!pip install num2words --quiet\n",
    "\n",
    "# Test imports\n",
    "try:\n",
    "    import num2words\n",
    "    print(\"✓ num2words imported successfully\")\n",
    "except ImportError as e:\n",
    "    print(f\"✗ num2words import failed: {e}\")\n",
    "\n",
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2758bd62",
   "metadata": {},
   "source": [
    "## Upload Images\n",
    "\n",
    "Upload your chart images or mount Google Drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3caf22dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Create images directory\n",
    "images_dir = Path(\"/content/chart_images\")\n",
    "images_dir.mkdir(exist_ok=True)\n",
    "\n",
    "print(\"Upload your chart images (PNG, JPG, etc.)\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "image_paths = []\n",
    "for filename, content in uploaded.items():\n",
    "    filepath = images_dir / filename\n",
    "    with open(filepath, 'wb') as f:\n",
    "        f.write(content)\n",
    "    image_paths.append(str(filepath))\n",
    "    print(f\"Uploaded: {filename}\")\n",
    "\n",
    "print(f\"\\nTotal images uploaded: {len(image_paths)}\")\n",
    "print(f\"Images directory: {images_dir}\")\n",
    "\n",
    "# Alternative: Mount Google Drive\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# images_dir = \"/content/drive/MyDrive/path/to/your/chart/images\"\n",
    "# image_paths = [os.path.join(images_dir, f) for f in os.listdir(images_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dee7d73",
   "metadata": {},
   "source": [
    "## Load Model from HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa4201c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from huggingface_hub import login\n",
    "from transformers import AutoProcessor, AutoModelForImageTextToText\n",
    "\n",
    "print(f\"Loading model: {model_id}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "\n",
    "# Authenticate if token provided\n",
    "if hf_token:\n",
    "    login(token=hf_token)\n",
    "    print(\"Authenticated with HuggingFace\")\n",
    "else:\n",
    "    print(\"No HF token provided - using public models only\")\n",
    "\n",
    "# Load processor\n",
    "print(\"Loading processor...\")\n",
    "processor = AutoProcessor.from_pretrained(model_id, trust_remote_code=True)\n",
    "print(\"✓ Processor loaded\")\n",
    "\n",
    "# Load model with appropriate dtype\n",
    "torch_dtype = torch.float16 if precision == \"fp16\" else torch.float32\n",
    "device = \"cuda\" if use_gpu and torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "print(f\"Loading model on {device} with dtype {torch_dtype}...\")\n",
    "model = AutoModelForImageTextToText.from_pretrained(\n",
    "    model_id,\n",
    "    trust_remote_code=True,\n",
    "    torch_dtype=torch_dtype\n",
    ").to(device)\n",
    "\n",
    "print(\"✓ Model loaded successfully\")\n",
    "print(f\"Device: {device}\")\n",
    "print(f\"Model dtype: {model.dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b31e3b",
   "metadata": {},
   "source": [
    "## Run Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745112a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from datetime import datetime\n",
    "from PIL import Image\n",
    "import time\n",
    "\n",
    "# Limit images if specified\n",
    "if image_limit > 0:\n",
    "    image_paths = image_paths[:image_limit]\n",
    "\n",
    "print(f\"Running inference on {len(image_paths)} images...\")\n",
    "\n",
    "results = []\n",
    "model.eval()\n",
    "\n",
    "for img_path in image_paths:\n",
    "    print(f\"Processing: {os.path.basename(img_path)}\")\n",
    "\n",
    "    row = {\n",
    "        'image_filename': os.path.basename(img_path),\n",
    "        'model_id': model_id,\n",
    "        'precision': precision,\n",
    "        'device': device,\n",
    "        'timestamp': datetime.now().isoformat(),\n",
    "        'response': None,\n",
    "        'error': None,\n",
    "        'latency_ms': None,\n",
    "        'memory_used_mb': None,\n",
    "        'tokens_generated': None,\n",
    "        'throughput_tokens_per_sec': None\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        # Load and prepare image\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "\n",
    "        # Prepare inputs\n",
    "        inputs = processor(images=img, return_tensors='pt')\n",
    "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "        # Reset memory stats\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "        # Run inference\n",
    "        start_time = time.perf_counter()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            generated = model.generate(**inputs, max_new_tokens=128)\n",
    "\n",
    "        end_time = time.perf_counter()\n",
    "\n",
    "        # Decode response\n",
    "        response = processor.batch_decode(generated, skip_special_tokens=True)[0]\n",
    "\n",
    "        # Calculate metrics\n",
    "        latency_ms = (end_time - start_time) * 1000\n",
    "        tokens_generated = generated.shape[-1] if hasattr(generated, 'shape') else len(generated[0]) if isinstance(generated, list) else None\n",
    "        throughput = tokens_generated / (end_time - start_time) if tokens_generated else None\n",
    "\n",
    "        memory_used_mb = None\n",
    "        if torch.cuda.is_available():\n",
    "            memory_used_mb = torch.cuda.max_memory_allocated() / (1024 * 1024)\n",
    "\n",
    "        row.update({\n",
    "            'response': response,\n",
    "            'latency_ms': round(latency_ms, 3),\n",
    "            'memory_used_mb': round(memory_used_mb, 3) if memory_used_mb else None,\n",
    "            'tokens_generated': tokens_generated,\n",
    "            'throughput_tokens_per_sec': round(throughput, 3) if throughput else None\n",
    "        })\n",
    "\n",
    "        print(f\"  ✓ Completed in {latency_ms:.1f}ms\")\n",
    "\n",
    "    except Exception as e:\n",
    "        row['error'] = str(e)\n",
    "        print(f\"  ✗ Error: {e}\")\n",
    "\n",
    "    results.append(row)\n",
    "\n",
    "print(f\"\\nInference completed. Processed {len(results)} images.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96373480",
   "metadata": {},
   "source": [
    "## Export Results to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e9113b",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = \"/content/benchmark_results.csv\"\n",
    "\n",
    "fieldnames = [\n",
    "    'image_filename', 'model_id', 'precision', 'device',\n",
    "    'latency_ms', 'memory_used_mb', 'tokens_generated', 'throughput_tokens_per_sec',\n",
    "    'timestamp', 'response', 'error'\n",
    "]\n",
    "\n",
    "with open(csv_path, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(results)\n",
    "\n",
    "print(f\"✓ Results saved to {csv_path}\")\n",
    "print(f\"Total results: {len(results)}\")\n",
    "\n",
    "# Display download link\n",
    "from google.colab import files\n",
    "files.download(csv_path)\n",
    "\n",
    "print(\"\\nDownload the CSV file above and copy it to your repository.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a44bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "files.download('/content/benchmark_results.csv')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
